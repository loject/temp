{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loject/temp/blob/master/Copy_of_Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z96nK57yHTt",
        "outputId": "f8fc1903-fe0f-4327-df62-1764b565ad53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import tensorflow\n",
        "print(\"Tensorflow version \" + tensorflow.__version__)\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/CNNv2'\n",
        "TRAIN_FILE = '/content/drive/MyDrive/CNNv2/formated.csv'"
      ],
      "metadata": {
        "id": "KkF0_3ovBsia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95272ad-af26-45bd-8585-77934ab5705e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import time, datetime\n",
        "\n",
        "def find_in_str(st, sub_str, pos):\n",
        "  last = 0\n",
        "  for i in range(pos):\n",
        "    last = st.find(sub_str, last + 1)\n",
        "  return last\n",
        "\n",
        "list_files = glob.glob(BASE_DIR + \"/*.csv\") \n",
        "open(TRAIN_FILE, 'w').close()\n",
        "for i in list_files:\n",
        "  print(os.path.abspath(i))\n",
        "  with open(i, 'r', encoding='utf-8') as f:\n",
        "      text = f.read()\n",
        "      text = text.split('\\n')\n",
        "      for j in range(len(text)):\n",
        "          elem = text[j]\n",
        "          if len(elem) < 1: continue\n",
        "          tm = datetime.datetime.strptime(elem.split(';')[3], '%H:%M:%S').time()\n",
        "          tmp = datetime.datetime.strptime(elem.split(';')[2], '%d/%m/%y') + datetime.timedelta(hours=tm.hour, minutes=tm.minute, seconds=tm.second)\n",
        "          text[j] = str(tmp.timestamp()) + elem[find_in_str(elem, ';', 4):]\n",
        "      \n",
        "      with open(TRAIN_FILE, 'a') as f:\n",
        "          for i in text:\n",
        "              f.write(\"%s\\n\" % i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHZt36pmrDWd",
        "outputId": "1dfe4fcf-7e31-4417-f65a-9c6d8d20685a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CNNv2/US1.BNGO_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.TBIO_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.TRIT_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.APP_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.GRUB_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.PFPT_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.DLO_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.MCFE_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.MIME_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.MNDY_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.TASK_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.MDRR_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.GHSI_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.ZCMD_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.SJ_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.VRME_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.KBNT_200120_220925.csv\n",
            "/content/drive/MyDrive/CNNv2/US1.IMNM_200120_220925.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import time, datetime\n",
        "\n",
        "def find_in_str(st, sub_str, pos):\n",
        "  last = 0\n",
        "  for i in range(pos):\n",
        "    last = st.find(sub_str, last + 1)\n",
        "  return last\n",
        "  \n",
        "\n",
        "def process_path(file_path):\n",
        "  with open(file_path) as f:\n",
        "    reader = csv.reader(f, delimiter=';')\n",
        "    data = [tuple(i) for i in reader]\n",
        "  X = np.array([data[i:i + inp_chars, :] for i in range(n)])\n",
        "  Y = data[inp_chars:]  # предсказание следующего символа\n",
        "  label = tensorflow.strings.split(file_path, os.sep)[-1]\n",
        "  value = tensorflow.strings.split(tensorflow.io.read_file(file_path))\n",
        "  return value, label\n",
        "\n",
        "def crutch_wrap(file_path):\n",
        "  return tensorflow.numpy_function(process_path, [file_path], [tensorflow.string, tensorflow.string])\n",
        "\n",
        "dataset = tensorflow.data.Dataset.list_files(TRAIN_FILE).map(crutch_wrap)\n",
        "\n",
        "print('asdjkf')\n",
        "for (i,j) in dataset:\n",
        "  try:\n",
        "    print(i.numpy()[0].decode('utf-8'))\n",
        "  except:\n",
        "    print('error\"')\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "PgpAtNJydYFs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "3449e79b-8d7d-4693-8a5e-0b9d3bd2baf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "asdjkf\n",
            "[('1579628100.0', '1.2100000', '1.2300000', '1.2000000', '1.2000000', '5382300'), ('1579628400.0', '1.2100000', '1.2100000', '1.1900000', '1.2041000', '5995800'), ('1579628700.0', '1.2000000', '1.2097000', '1.1900000', '1.2002000', '3033100'), ('1579629000.0', '1.2000000', '1.2200000', '1.2000000', '1.2200000', '1099800'), ('1579629300.0', '1.2140000', '1.2200000', '1.2000000', '1.2196000', '2921600'), ('1579629600.0', '1.2150000', '1.2150000', '1.2050000', '1.2050000', '2460900'), ('1579629900.0', '1.2050000', '1.2100000', '1.2000000', '1.2076000', '1060800'), ('1579630200.0', '1.2012000', '1.2100000', '1.2012000', '1.2100000', '1088600'), ('1579630500.0', '1.2100000', '1.2114000', '1.1900000', '1.1950000', '5202800'), ('1579630800.0', '1.1999000', '1.2000000', '1.1850000', '1.1950000', '2491200')]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-eef125d81916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'asdjkf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    820\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2921\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2923\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2924\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: NameError: name 'n' is not defined\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-51-eef125d81916>\", line 17, in process_path\n    X = np.array([data[i:i + inp_chars, :] for i in range(n)])\n\nNameError: name 'n' is not defined\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inp_chars = 6\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input((1, 1)))  # при тренировке в рекуррентные модели keras подается сразу вся последовательность, поэтому в input теперь два числа. 1-длина последовательности, 2-размер OHE\n",
        "model.add(SimpleRNN(128, activation='tanh'))  # рекуррентный слой на 500 нейронов\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "# history = model.fit(X, Y, batch_size=32, epochs=100)\n",
        "\n",
        "print(os.listdir(BASE_DIR))\n",
        "# def buildPhrase(inp_str, str_len=50):\n",
        "#     for i in range(str_len):\n",
        "#         x = []\n",
        "#         for j in range(i, i + inp_chars):\n",
        "#             x.append(tokenizer.texts_to_matrix(inp_str[j]))  # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "#         x = np.array(x)\n",
        "#         inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "#         pred = model.predict(inp)  # предсказываем OHE четвертого символа\n",
        "#         d = tokenizer.index_word[pred.argmax(axis=1)[0]]  # получаем ответ в символьном представлении\n",
        "\n",
        "#         inp_str += d  # дописываем строку\n",
        "\n",
        "#     return inp_str\n",
        "\n",
        "\n",
        "# res = buildPhrase(\"утренн\")\n",
        "# print(res)"
      ],
      "metadata": {
        "id": "e-2qL3I2Bwup",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "1615f78c-4866-44cf-b4a2-872dab3f6826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeWidth(0, true, {maxWidth: 5000})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeWidth(0, true, {maxWidth: 5000})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 128)               16640     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,769\n",
            "Trainable params: 16,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['war and peace.txt', 'US1.BNGO_200120_220925.txt', 'US1.TBIO_200120_220925.txt', 'US1.APP_200120_220925.txt', 'US1.PFPT_200120_220925.txt', 'US1.DLO_200120_220925.txt', 'US1.MCFE_200120_220925.txt', 'US1.MIME_200120_220925.txt', 'US1.MNDY_200120_220925.txt', 'US1.TASK_200120_220925.txt', 'US1.MDRR_200120_220925.txt', 'US1.VRME_200120_220925.txt', 'US1.KBNT_200120_220925.txt', 'US1.IMNM_200120_220925.txt', 'US1.ONCR_200120_220925.txt', 'US1.JUPW_200120_220925.txt', 'US1.ABST_200120_220925.txt', 'US1.INM_200120_220925.txt', 'US1.LIXT_200120_220925.txt', 'US1.SCPS_200120_220925.txt', 'US1.COMS_200120_220925.txt', 'US1.DFH_200120_220925.txt', 'US1.PAX_200120_220925.txt', 'US1.RELI_200120_220925.txt', 'US1.VLON_200120_220925.txt', 'US1.SNCY_200120_220925.txt', 'US1.ALF_200120_220925.txt', 'US1.IFBD_200120_220925.txt', 'US1.SKYT_200120_220925.txt', 'US1.SWIM_200120_220925.txt', 'US1.DIBS_200120_220925.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from matplotlib import pyplot as plt\n",
        "# train, test = tf.keras.datasets.mnist.load_data()\n",
        "# id = 1\n",
        "\n",
        "# print(train[0][id])\n",
        "# print(\"test[0]\")\n",
        "# print(train[1][id])\n",
        "\n",
        "# plt.figure()\n",
        "\n",
        "# for i in range(35):\n",
        "#   plt.imshow(train[0][i], cmap='gray')\n",
        "#   plt.show()\n",
        "\n",
        "# images, labels = train\n",
        "# images = images/255.0\n",
        "# labels = labels.astype(np.int32)\n",
        "\n",
        "# fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "# fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
        "\n",
        "# # model = tf.keras.Sequential([\n",
        "# #   tf.keras.layers.Flatten(),\n",
        "# #   tf.keras.layers.Dense(10)\n",
        "# # ])\n",
        "\n",
        "# # model.compile(optimizer='adam',\n",
        "# #               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "# #               metrics=['accuracy'])\n",
        "\n",
        "# # model.fit(fmnist_train_ds, epochs=2)\n",
        "\n",
        "# # loss, accuracy = model.evaluate(fmnist_train_ds)\n",
        "# # print(\"Loss :\", loss)\n",
        "# # print(\"Accuracy :\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CqfR1TmNsNrF",
        "outputId": "35e75fa7-31b5-4dc2-9d4f-9d3a40ac5ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeWidth(0, true, {maxWidth: 5000})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeWidth(0, true, {maxWidth: 5000})"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyMPVsxAVYP4WzQ+HjhMaFv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}